{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80748d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for POI_FINAL_Museum.csv:\n",
      "                Name   Latitude  Longitude  Weighted Sum  Rank\n",
      "0            Jane A.  40.767370 -73.981125 -4.000000e-01   6.0\n",
      "1           Spyscape  40.765198 -73.983618  2.000000e-01   4.0\n",
      "2         The Africa  40.796289 -73.949378 -5.000000e+00  10.0\n",
      "3    Madame Tussauds  40.756539 -73.988521 -3.400000e+00   9.0\n",
      "4           New York  40.752895 -73.977589 -6.000000e-01   7.0\n",
      "5         Center for  40.752768 -73.992304 -2.600000e+00   8.0\n",
      "6  Fashion Institute  40.747304 -73.994797  4.200000e+00   2.0\n",
      "7       Hebrew Union  40.728807 -73.994549  1.665335e-16   5.0\n",
      "8         Lower East  40.724864 -73.992735  5.400000e+00   1.0\n",
      "9            The New  40.726021 -73.999809  2.200000e+00   3.0\n",
      "\n",
      "\n",
      "Results for POI_FINAL_Restaurant.csv:\n",
      "                    Name   Latitude  Longitude  Weighted Sum  Rank\n",
      "0       Daily Provisions  40.782225 -73.978646           0.3   5.0\n",
      "1          Levain Bakery  40.781511 -73.979099           1.2   3.0\n",
      "2            Sushi Kaito  40.779232 -73.983555          -3.5   9.0\n",
      "3                 By The  40.778060 -73.956894          -6.1  10.0\n",
      "4          Levain Bakery  40.777395 -73.955514           0.3   5.0\n",
      "5          Breads Bakery  40.771077 -73.981750           2.7   2.0\n",
      "6          Empanada Mama  40.764419 -73.988481          -1.1   8.0\n",
      "7            Bo's Bagels  40.804260 -73.954145           0.9   4.0\n",
      "8  UrbanSpace Vanderbilt  40.754438 -73.976426           0.2   7.0\n",
      "9       Boqueria Spanish  40.755471 -73.990095           5.1   1.0\n",
      "\n",
      "\n",
      "Results for POI_FINAL_Travel_Agency.csv:\n",
      "                      Name   Latitude  Longitude  Weighted Sum  Rank\n",
      "0               DFC Travel  40.787374 -73.975875          -4.4  10.0\n",
      "1                KG Travel  40.773881 -73.947643           0.8   5.0\n",
      "2                  Hotwire  40.763570 -73.985957          -0.3   7.0\n",
      "3        BlueOrange Travel  40.762041 -73.984630           2.4   2.0\n",
      "4  Protravel International  40.759743 -73.973793           0.8   6.0\n",
      "5        Gad International  40.756935 -73.977877          -1.9   8.0\n",
      "6         Empire Limousine  40.757123 -73.986884          -2.6   9.0\n",
      "7                 Certares  40.754604 -73.978267           2.9   1.0\n",
      "8         Executive Global  40.757527 -73.989914           1.3   3.0\n",
      "9              Encore Jets  40.755089 -73.986280           1.0   4.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# List of CSV files\n",
    "csv_files = ['POI_FINAL_Museum.csv', 'POI_FINAL_Restaurant.csv', 'POI_FINAL_Travel_Agency.csv']\n",
    "\n",
    "weights = {\n",
    "        'Distance': 0.2,\n",
    "        'Popularity': 0.1,\n",
    "        'Ratings': 0.3,\n",
    "        'Total Ratings': 0.1,\n",
    "        'Price($)': 0.3\n",
    "}\n",
    "    \n",
    "for file in csv_files:\n",
    "    # Read the CSV file\n",
    "    data = pd.read_csv(file, encoding='latin1')\n",
    "    \n",
    "    # Normalize the data\n",
    "    for criterion in weights.keys():\n",
    "        if criterion == 'Price($)':\n",
    "            data[criterion] = (data[criterion].max() - data[criterion]) / (data[criterion].max() - data[criterion].min())\n",
    "        else:\n",
    "            data[criterion] = (data[criterion] - data[criterion].min()) / (data[criterion].max() - data[criterion].min())\n",
    "    \n",
    "    # Calculate the weighted sum using Promethee\n",
    "    weighted_sum = np.zeros(len(data))\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data)):\n",
    "            if i != j:\n",
    "                pref_ij = np.sum([int(data.iloc[i][criterion] > data.iloc[j][criterion]) * weights[criterion] for criterion in weights.keys()])\n",
    "                pref_ji = np.sum([int(data.iloc[j][criterion] > data.iloc[i][criterion]) * weights[criterion] for criterion in weights.keys()])\n",
    "                weighted_sum[i] += pref_ij - pref_ji\n",
    "    \n",
    "    # Add the weighted sums to the DataFrame\n",
    "    data['Weighted Sum'] = weighted_sum\n",
    "    \n",
    "    # Rank the alternatives based on the weighted sum\n",
    "    data['Rank'] = data['Weighted Sum'].rank(ascending=False, method='min')\n",
    "    \n",
    "    # Display the result\n",
    "    print(f\"Results for {file}:\")\n",
    "    # Truncate the name\n",
    "    data['Name'] = data['Name'].apply(lambda x: ' '.join(x.split()[:2]))\n",
    "    print(data[['Name', 'Latitude', 'Longitude', 'Weighted Sum', 'Rank']])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237ff3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
